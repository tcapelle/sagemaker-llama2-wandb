{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2535250-4a91-4979-bb73-8b2badb5927b",
   "metadata": {},
   "source": [
    "# Train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf85846-dd89-4e82-a2b2-add438e04b37",
   "metadata": {},
   "source": [
    "We need to save our W&B credentials on the folder that will be copied to the SM instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab9da8d-990c-4bc8-88c0-cbb22e5af717",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uqqq sagemaker wandb huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583bb8c8-4b07-416a-b7e8-b04bdfecb523",
   "metadata": {},
   "source": [
    "save your wandb API token to the script folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54956c0-214d-435d-a8ee-a463eba71b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.sagemaker_auth(path=\"scripts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a531a615-0095-43d3-8559-72940752ca72",
   "metadata": {},
   "source": [
    "## SageMaker auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daefd8c2-7f14-4411-8bee-2780af416edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "DATASET_S3 = f's3://{sess.default_bucket()}/processed/wandbot/train'\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7e817f-7f81-49d1-b260-0e033b405db6",
   "metadata": {},
   "source": [
    "## Loading the data from W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c39de9-f883-4d5c-8fac-61a092a1a4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dataset we pre-tokenized and created before\n",
    "AT_ADDRESS = \"capecape/aws_llm_workshop/wandbot_dataset_tokenized:v0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fc1f54-3710-401a-b34c-3341bb9e3f50",
   "metadata": {},
   "source": [
    "We put inside the `run_clm.py` file the loading from a W&B Artifact:\n",
    "\n",
    "```python\n",
    "import wandb\n",
    "from datasets import load_from_disk\n",
    "\n",
    "def load_from_artifact(at_address, at_type=\"dataset\"):\n",
    "    \"Load a HF dataset from a W&B artifact\"\n",
    "    artifact = wandb.use_artifact(at_address, type=at_type)\n",
    "    artifact_dir = artifact.download()\n",
    "    return load_from_disk(artifact_dir)\n",
    "\n",
    "...\n",
    "    ds = load_from_artifact(AT_ADDRESS)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70914d3a-7f0a-4d3e-b962-11c48a82facf",
   "metadata": {},
   "source": [
    "## Train time! ðŸš‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de91d8e5-4f7e-4a2a-a5cc-53cd1f1b68a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "WANDB_PROJECT = \"aws_llm_workshop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfe6c7d-c28b-4909-bced-63d19f6d96d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "from huggingface_hub import HfFolder\n",
    "\n",
    "# define Training Job Name \n",
    "MODEL_NAME = \"codellama/CodeLlama-7b-Instruct-hf\"\n",
    "job_name = 'wandb-qlora-codellama7'\n",
    "\n",
    "lr = 2e-4\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters = {\n",
    "    'model_id': MODEL_NAME,                           # pre-trained model\n",
    "    # 'dataset_artifact': AT_ADDRESS,                   # Artifact containing the dataset at W&B\n",
    "    # 'dataset_path': '/opt/ml/input/data/training',    # path where sagemaker will save training dataset\n",
    "    'dataset_path': AT_ADDRESS,\n",
    "    'epochs': 1,                                      # number of training epochs\n",
    "    'per_device_train_batch_size': 2,                 # batch size for training\n",
    "    'lr': lr,                                         # learning rate used during training\n",
    "    'hf_token': HfFolder.get_token(),                 # huggingface token to access llama 2\n",
    "    'merge_weights': True,                            # wether to merge LoRA into the model (needs more memory)\n",
    "    'report_to': \"wandb\",                              # report to wandb\n",
    "    'wandb_project': WANDB_PROJECT,\n",
    "    \"run_name\":  f\"{MODEL_NAME}__qlora\",\n",
    "}\n",
    "    \n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point          = 'run_clm.py',      # train script\n",
    "    source_dir           = 'scripts',         # directory which includes all the files needed for training\n",
    "    instance_type        = 'ml.g5.4xlarge',   # instances type used for the training job\n",
    "    instance_count       = 1,                 # the number of instances used for training\n",
    "    base_job_name        = job_name,          # the name of the training job\n",
    "    role                 = role,              # Iam role used in training job to access AWS ressources, e.g. S3\n",
    "    volume_size          = 300,               # the size of the EBS volume in GB\n",
    "    transformers_version = '4.28',            # the transformers version used in the training job\n",
    "    pytorch_version      = '2.0',             # the pytorch_version version used in the training job\n",
    "    py_version           = 'py310',           # the python version used in the training job\n",
    "    hyperparameters      =  hyperparameters,  # the hyperparameters passed to the training job\n",
    "    environment          = { \"HUGGINGFACE_HUB_CACHE\": \"/tmp/.cache\"}, # set env variable to cache models in /tmp\n",
    "    disable_output_compression = True         # not compress output to save training time and cost\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b69d526-9d4f-4b4b-8070-c4fc501d20d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a data input dictonary with our uploaded s3 uris\n",
    "data = {'training': DATASET_S3}\n",
    "\n",
    "# data = {}\n",
    "# starting the train job with our uploaded datasets as input\n",
    "huggingface_estimator.fit(data, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37314fb0-78a5-45d4-afb0-dd900e54767d",
   "metadata": {},
   "source": [
    "## Link Model Hack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceaff5a-2f67-44b4-ad4d-8953f4955a0f",
   "metadata": {},
   "source": [
    "I have to pull the image URI manually here, there is probably a better way..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec642c4-aebf-4c58-b72a-87ffdc8ad102",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = \"wandb-qlora-codellama7-2023-10-25-13-33-31-404-7cd3bc-algo-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31549c29-bfdc-475f-a447-3af44b6c0b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_URI = \"s3://sagemaker-us-east-1-372108735839/wandb-qlora-codellama7-2023-10-25-13-33-31-404/output/model/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e908deb-6199-4816-9959-12871fb0d5a5",
   "metadata": {},
   "source": [
    "I am passing the `run_id` so we get the artifact logged on the same experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b973944-a8ec-4aa6-b4c0-2d93f74c051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with wandb.init(project=WANDB_PROJECT, id=run_id):\n",
    "    at = wandb.Artifact(name=\"codellama7_wandb\", \n",
    "                        type=\"model\",\n",
    "                        description=\"A CodeLlama7B expert on W&B\")\n",
    "    at.add_reference(S3_URI)\n",
    "    wandb.log_artifact(at)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

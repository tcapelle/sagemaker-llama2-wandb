{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f16e594-1ba8-4caf-8127-30d3a51c5790",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qqqU sagemaker wandb datasets transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7082c65b-dabb-4b77-9df8-c5687a78753c",
   "metadata": {},
   "outputs": [],
   "source": [
    "WANDB_PROJECT = \"aws_llm_workshop\"\n",
    "USE_S3 = True\n",
    "\n",
    "RAW_TRAIN_DATASET_ARTIFACT = 'capecape/wandbot/run-m6nz6yrl-wandbot_questions:v0'\n",
    "RAW_EVAL_DATASET_ARTIFACT  = \"wandbot/wandbot-eval/run-kinbxic4-responses:v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5380e7bd-66f3-4237-a901-fe935a249982",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"codellama/CodeLlama-7b-Instruct-hf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f2b7e0-dab7-46aa-b287-9721efb8dae3",
   "metadata": {},
   "source": [
    "# Preparing Data\n",
    "How to prepare our dataset for model Finetune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25424b4f-e709-4663-beae-5a708e491db0",
   "metadata": {},
   "source": [
    "## SageMaker auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee341747-68ae-4b11-ab7c-2e5b86bf89ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0a3457-8941-45d5-9ff8-eef4fa936a7b",
   "metadata": {},
   "source": [
    "## Formatting the data for the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ca2daa-0c44-4ac1-ba98-1d70f87fd3e8",
   "metadata": {},
   "source": [
    "A big part of training LLMs lives in getting the data formatted correctly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6df869f-739b-409d-a50a-495dad432777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d27c251-56b5-4f64-9268-ebc900720a7f",
   "metadata": {},
   "source": [
    "let's create a run and monitor our work from there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569d476a-9eae-4bcd-837d-2cc7f55f62b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=WANDB_PROJECT, job_type=\"text_formatting\")\n",
    "\n",
    "# this way we get tracebility\n",
    "dataset_artifact = wandb.use_artifact(RAW_TRAIN_DATASET_ARTIFACT)\n",
    "table = dataset_artifact.get(\"wandbot_questions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f902fa8-1b3c-4f19-af81-94372c0a16f7",
   "metadata": {},
   "source": [
    "this is a W&B table, so we can convert it to whatever format we may need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372833dc-d535-464e-936e-765731418b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(table.data, columns=table.columns)\n",
    "df = df.dropna()\n",
    "df = df.assign(context_len = lambda df: df.page_content.str.len()/3.6)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61c89c2-831f-4996-9f07-3965ba839858",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90391542-9e78-46ea-a197-0bc915f54a44",
   "metadata": {},
   "source": [
    "Let's prepare the training dataset now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dae08b1-5519-43e4-ba28-099950a0bd63",
   "metadata": {},
   "source": [
    "If you use CodeLLama we need to format the instructions accordingly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb5948d-1b37-46b6-b6e1-5b1c65498bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_INST, E_INST = \"[INST] \", \" [/INST]\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "EOS = \"</s>\"\n",
    "\n",
    "prompt_format = (\n",
    "    B_INST\n",
    "    + B_SYS\n",
    "    + \"You are an AI assistant designed to assist developers with everyday tasks related to Weight & Biases \"\n",
    "    + \"and provide helpful information. As an expert in the open-source python SDK wandb answer the following \"\n",
    "    # + \"question based on the context below. Answer in formatted Markdown.\\n\"\n",
    "    + \"question below. Answer in formatted Markdown.\\n\"\n",
    "    + \"{page_content}\"\n",
    "    + E_SYS\n",
    "    + \"{question}\"\n",
    "    + E_INST\n",
    "    + \"\\n[W&B]\\n\"\n",
    "    + \"{answer}\"\n",
    "    + \"\\n[/W&B]\"\n",
    "    + EOS\n",
    ")\n",
    "\n",
    "def format_text(row):\n",
    "    return prompt_format.format_map(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ab80e2-9206-421e-acf9-d1d8d67baab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da903861-dce9-466d-839e-67d937b228e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_example = format_text(df.iloc[0])\n",
    "print(one_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf19de4-c29a-4803-aad1-8eb0b9c32da5",
   "metadata": {},
   "source": [
    "Let's compute the format over all the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369e92cb-d51d-4f97-93e0-bb3c709eb126",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df.apply(format_text, axis=1)\n",
    "\n",
    "# print(df.iloc[200][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18f6fe4-6573-4901-ac44-aa51d0400452",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(\"wandb_questions_ds.jsonl\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01efd5c0-1fec-4c76-bd6e-1ab182deb7c3",
   "metadata": {},
   "source": [
    "## Saving your work to W&B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3867767-df18-4866-9c78-ca623ad9b205",
   "metadata": {},
   "source": [
    "We should log this to W&B so we can inspect the dataset interactively using W&B Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902581de-ada6-44c4-b399-ef24845948e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = wandb.Table(dataframe=df)\n",
    "wandb.log({\"wandb_questions_ds\": table})\n",
    "\n",
    "# let's also save a the dataset at this stage\n",
    "at = wandb.Artifact(\n",
    "    name=\"wandb_questions_ds\", \n",
    "    type=\"dataset\",\n",
    "    description=\"A wandbot dataset of questions and answers about W&B for training (non tokenized)\",\n",
    "    metadata={\"prompt_format\": prompt_format,\n",
    "              \"length\": len(df),\n",
    "             }\n",
    ")\n",
    "at.add_file(\"wandb_questions_ds.jsonl\")\n",
    "wandb.log_artifact(at)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdebe295-f927-406f-b790-27bc059abab1",
   "metadata": {},
   "source": [
    "## Tokenizing and saving the preprocessing\n",
    "We can save time during training by pre-processing the dataset and loading directly a tokenized dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aaffb3-d181-4c34-a58d-3e9c78a16d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_auth_token=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03ed5fc-a178-424d-8bc5-56f452dc3487",
   "metadata": {},
   "source": [
    "we can convert the data to a huggingface parquet-based dataset for fast loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ad3e77-c60c-46a1-9fef-432d412bccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=WANDB_PROJECT, job_type=\"tokenizing\")\n",
    "artifact = wandb.use_artifact('capecape/aws_llm_workshop/wandb_questions_ds:v0', type='dataset')\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d894909-a161-4806-832f-0da72a580860",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(\n",
    "    path=\".\", \n",
    "    data_files=f\"{artifact_dir}/wandb_questions_ds.jsonl\", \n",
    "    split=\"train\")\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676fbde0-d780-4beb-94dd-fff1a5a617ac",
   "metadata": {},
   "source": [
    "one sample looks like this ðŸ‘‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4aa0e2-c9b3-4065-8c4a-ca24f8bfd856",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.select_columns([\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5df85d-be1f-4726-92c8-73e94146ea5c",
   "metadata": {},
   "source": [
    "### Packing and chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac52401-ea01-44bb-95d7-b11f8aa34b59",
   "metadata": {},
   "source": [
    "We define some helper functions to pack our samples into sequences of a given length and then tokenize them.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eb36f2-6dbf-4f13-b8ea-1ba2effc709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "# template dataset to add prompt to each sample\n",
    "def template_dataset(sample):\n",
    "    sample[\"text\"] = f\"{sample}{tokenizer.eos_token}\"\n",
    "    return sample\n",
    "\n",
    "\n",
    "# apply prompt template per sample\n",
    "train_dataset = train_dataset.map(template_dataset)\n",
    "# print random sample\n",
    "print(train_dataset[randint(0, len(train_dataset))][\"text\"])\n",
    "\n",
    "# empty list to save remainder from batches to use in next batch\n",
    "remainder = {\"input_ids\": [], \"attention_mask\": [], \"token_type_ids\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8e2766-5b3a-4424-82e6-1cf5ef45da1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk(sample, chunk_length=1024):\n",
    "    # define global remainder variable to save remainder from batches to use in next batch\n",
    "    global remainder\n",
    "    # Concatenate all texts and add remainder from previous batch\n",
    "    concatenated_examples = {k: list(chain(*sample[k])) for k in sample.keys()}\n",
    "    concatenated_examples = {k: remainder[k] + concatenated_examples[k] for k in concatenated_examples.keys()}\n",
    "    # get total number of tokens for batch\n",
    "    batch_total_length = len(concatenated_examples[list(sample.keys())[0]])\n",
    "\n",
    "    # get max number of chunks for batch\n",
    "    if batch_total_length >= chunk_length:\n",
    "        batch_chunk_length = (batch_total_length // chunk_length) * chunk_length\n",
    "\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + chunk_length] for i in range(0, batch_chunk_length, chunk_length)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    # add remainder to global variable for next batch\n",
    "    remainder = {k: concatenated_examples[k][batch_chunk_length:] for k in concatenated_examples.keys()}\n",
    "    # prepare labels\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "\n",
    "# tokenize and chunk dataset\n",
    "lm_dataset = train_dataset.map(\n",
    "    lambda sample: tokenizer(sample[\"text\"]), batched=True, remove_columns=list(train_dataset.features)\n",
    ").map(\n",
    "    partial(chunk, chunk_length=1024),\n",
    "    batched=True,\n",
    ")\n",
    "\n",
    "# Print total number of samples\n",
    "print(f\"Total number of samples: {len(lm_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd4726a-5381-4a56-8e5a-59fdfffb8c7c",
   "metadata": {},
   "source": [
    "## Save to a bucket and W&B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb0ecae-ed90-4f83-a34d-99e46daa4d1b",
   "metadata": {},
   "source": [
    "We are now going to use W&B Aritfacts integration with S3 buckets, so our dataset is close to the training compute SM instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322268d9-80a8-4f67-bf55-76cf4773ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train_dataset to s3\n",
    "if USE_S3:\n",
    "    training_input_path = f's3://{sess.default_bucket()}/processed/wandbot/train'\n",
    "else:\n",
    "    training_input_path = \"./wandbot_train_ds\"\n",
    "\n",
    "lm_dataset.save_to_disk(training_input_path)\n",
    "\n",
    "print(\"uploaded data to:\")\n",
    "print(f\"training dataset to: {training_input_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92d3c9a-f01d-4b6e-8a20-ab707918a0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "at = wandb.Artifact(\n",
    "    name=\"wandbot_dataset_tokenized\", \n",
    "    type=\"dataset\",\n",
    "    description=\"A wandbot dataset of questions and answers about W&B - CodeLLama tokenized\",\n",
    "    metadata={\"model_name\": MODEL_NAME, \"tokenizer\": MODEL_NAME},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edcf658-cd05-46de-bc30-45c27a8f4853",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_S3:\n",
    "    at.add_reference(training_input_path)\n",
    "else:\n",
    "    at.add_dir(training_input_path)\n",
    "wandb.log_artifact(at)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbd2e08-939d-4269-8d65-8ae3684fb3de",
   "metadata": {},
   "source": [
    "Let's finish this run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3900fa-e7b2-4b59-be6f-d9d2459e237c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b63367-19f7-4bb6-b2f8-44e200c74df6",
   "metadata": {},
   "source": [
    "# Eval Dataset\n",
    "We prepared a set of questions from `wandbot` that were gathered and curated by my colleague Ayush T. God's work here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d607bff-cbbd-4554-822f-a0fbabe0c659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import wandb\n",
    "import pandas as pd\n",
    "\n",
    "wandb.init(project=WANDB_PROJECT, job_type=\"eval_preprocessing\")\n",
    "question_artifacts = wandb.use_artifact(RAW_EVAL_DATASET_ARTIFACT)\n",
    "\n",
    "with open(question_artifacts.file()) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "columns = data[\"columns\"]\n",
    "data = data[\"data\"]\n",
    "eval_df = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c78e291-ce2d-4061-9720-71f8bdf317ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb58d1b-0b17-49e3-8768-b9baeb3d9046",
   "metadata": {},
   "source": [
    "Let's remove retrieved Japanese text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646a2941-5ea9-47be-98e2-8731387f6114",
   "metadata": {},
   "source": [
    "### Clean up and prepare (pandas workout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee50101-b6a7-4e08-ab2f-e426b5e9840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_japanese(text):\n",
    "    for char in text:\n",
    "        if 'ä¸€' <= char <= 'é¾¥':\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365bff6a-c0bc-4765-8044-854df497d29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"## WandbCallback å¼•æ•°\\n\\n| å¼•æ•° | ä½¿ç”¨æ³• |\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addabb0a-5569-4c26-9b29-17484a20832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df[\"retrieved_context_en\"] = [[ctx for ctx in ctxs if not contains_japanese(ctx)] for ctxs in eval_df.retrieved_context.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd18bd4e-aeb5-4ac7-a547-08252188b048",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0157fa00-a477-4394-9517-0568a58d392c",
   "metadata": {},
   "source": [
    "Just keep the first page results, to save memory..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b8732a-e42e-4f19-b8ee-baceb673f32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df[\"retrieved_context_first\"] = [ctxs[0] for ctxs in eval_df.retrieved_context_en.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14459a92-98fe-4674-9e8a-7afdaf7c1095",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dd549f-1923-4e81-ba84-a5fa5dcbb297",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = eval_df.assign(tokens = eval_df['retrieved_context_first'].str.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37a312e-08cf-4406-99d5-87342709dcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f78893-9828-4c35-b5e6-a84b5a32134b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = eval_df[[\"query\", \"generated_response\", \"retrieved_context_first\", \"tokens\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e8f2c5-1c1a-4cc7-9419-bf2e8749cb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.columns = [\"question\", \"answer\", \"retrieved_context\", \"char_len\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e7ff7d-27fe-4e9d-b04a-98a9494387c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = eval_df.rename({\"retrieved_context\": \"page_content\"}, axis=1)\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f8de07-59c4-40f0-810b-7a1805ab5a8a",
   "metadata": {},
   "source": [
    "## Save to W&B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108ce808-876b-404d-bc98-eba585672252",
   "metadata": {},
   "source": [
    "Let's format the dataset in the same way we created the training dataset, we have to be consisten with naming\n",
    "- We remove the answer, but we are going to keep it on the dataset to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664f5165-0d3d-4e19-b237-2d9c198c5c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_INST, E_INST = \"[INST] \", \" [/INST]\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "EOS = \"</s>\"\n",
    "\n",
    "eval_prompt_format = (\n",
    "    B_INST\n",
    "    + B_SYS\n",
    "    + \"You are an AI assistant designed to assist developers with everyday tasks related to Weight & Biases\"\n",
    "    + \"and provide helpful information. As an expert in the open-source python SDK wandb answer the following\"\n",
    "    # + \"question based on the context below. Answer in formatted Markdown.\\n\"\n",
    "    + \"question below. Answer in formatted Markdown.\\n\"\n",
    "    + \"{page_content}\"\n",
    "    + E_SYS\n",
    "    + \"{question}\"\n",
    "    + E_INST\n",
    "    + \"\\n[W&B]\\n\"\n",
    "    # + \"{answer}\"\n",
    "    # + \"\\n[/W&B]\"\n",
    "    # + EOS\n",
    ")\n",
    "\n",
    "def eval_format_text(row):\n",
    "    return eval_prompt_format.format_map(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb560592-dbef-4da7-a9cb-a3463341910c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df[\"text\"] = eval_df.apply(eval_format_text, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29f448b-07a4-4dc9-8621-98d50a9edcd0",
   "metadata": {},
   "source": [
    "Save to disk and create HF dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6808da60-9b6e-43d7-a893-df1c677087b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6c968a-892d-4d76-a921-63a473bc71dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.to_json(\"wandbot_eval.jsonl\", orient='records', lines=True)\n",
    "eval_dataset = load_dataset(\".\", data_files=\"wandbot_eval.jsonl\")\n",
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd86384-2cae-41f8-83a5-6597242244db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train_dataset to s3\n",
    "if USE_S3:\n",
    "    eval_input_path = f's3://{sess.default_bucket()}/processed/wandbot/eval'\n",
    "else:\n",
    "    eval_input_path = \"./wandbot_eval_ds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4c5caf-c577-4360-881d-ef36b5bb39d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset.save_to_disk(eval_input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9a87e0-d691-4076-8894-c5f4157bdf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = wandb.Table(dataframe=eval_df)\n",
    "wandb.log({\"wandbot_eval_dataset\": table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d615bb7-f385-4771-a593-c2845561d0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "at = wandb.Artifact(\n",
    "    name=\"wandbot_eval_dataset\", \n",
    "    type=\"dataset\",\n",
    "    description=\"A wandbot dataset of questions and answers about W&B for evaluation\",\n",
    "    metadata={\"prompt_format\": eval_prompt_format,\n",
    "              \"length\": len(eval_dataset),\n",
    "             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b87fb8c-c12e-4f63-b9d2-6ef7d014db1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_S3:\n",
    "    at.add_reference(eval_input_path)\n",
    "else:\n",
    "    at.add_dir(eval_input_path)\n",
    "wandb.log_artifact(at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab877b6f-28e2-4d2d-bf28-86cba3736dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ffd90e-d069-42bf-a3de-bbcfa74f7e23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

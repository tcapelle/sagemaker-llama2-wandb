{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f16e594-1ba8-4caf-8127-30d3a51c5790",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -qqqU sagemaker wandb datasets transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7082c65b-dabb-4b77-9df8-c5687a78753c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "WANDB_PROJECT = \"aws_llm_demo\"\n",
    "USE_S3 = True\n",
    "\n",
    "RAW_TRAIN_DATASET_ARTIFACT = 'capecape/wandbot/run-m6nz6yrl-wandbot_questions:v0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f2b7e0-dab7-46aa-b287-9721efb8dae3",
   "metadata": {},
   "source": [
    "# Preparing Data\n",
    "How to prepare our dataset for model Finetune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25424b4f-e709-4663-beae-5a708e491db0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SageMaker auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee341747-68ae-4b11-ab7c-2e5b86bf89ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker role arn: arn:aws:iam::372108735839:role/SageMakerExecutionRole\n",
      "sagemaker bucket: sagemaker-us-east-1-372108735839\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0a3457-8941-45d5-9ff8-eef4fa936a7b",
   "metadata": {},
   "source": [
    "## Formatting the data for the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ca2daa-0c44-4ac1-ba98-1d70f87fd3e8",
   "metadata": {},
   "source": [
    "A big part of training LLMs lives in getting the data formatted correctly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6df869f-739b-409d-a50a-495dad432777",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d27c251-56b5-4f64-9268-ebc900720a7f",
   "metadata": {},
   "source": [
    "let's create a run and monitor our work from there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "569d476a-9eae-4bcd-837d-2cc7f55f62b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcapecape\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/sagemaker-llama2-wandb/training/wandb/run-20231017_101155-cp1x98ab</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/capecape/aws_llm_demo/runs/cp1x98ab' target=\"_blank\">efficient-salad-36</a></strong> to <a href='https://wandb.ai/capecape/aws_llm_demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/capecape/aws_llm_demo' target=\"_blank\">https://wandb.ai/capecape/aws_llm_demo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/capecape/aws_llm_demo/runs/cp1x98ab' target=\"_blank\">https://wandb.ai/capecape/aws_llm_demo/runs/cp1x98ab</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "wandb.init(project=WANDB_PROJECT, job_type=\"text_formatting\")\n",
    "\n",
    "# this way we get tracebility\n",
    "dataset_artifact = wandb.use_artifact(RAW_TRAIN_DATASET_ARTIFACT)\n",
    "table = dataset_artifact.get(\"wandbot_questions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f902fa8-1b3c-4f19-af81-94372c0a16f7",
   "metadata": {},
   "source": [
    "this is a W&B table, so we can convert it to whatever format we may need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "372833dc-d535-464e-936e-765731418b46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>page_content</th>\n",
       "      <th>metadata</th>\n",
       "      <th>context_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A user has just started using the Weights &amp; Bi...</td>\n",
       "      <td>What is a 'run' in W&amp;B and what can I use it for?</td>\n",
       "      <td>A 'run' in W&amp;B is the fundamental unit that yo...</td>\n",
       "      <td>import Tabs from ‚Äò@theme/Tabs‚Äô;  \\n\\nimport Ta...</td>\n",
       "      <td>{'file_type': '.md', 'language': 'en', 'source...</td>\n",
       "      <td>1291.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A user has just started using W&amp;B and they are...</td>\n",
       "      <td>Hi! I'm new to W&amp;B and I'm a bit stuck. Can yo...</td>\n",
       "      <td>Sure, you can install the W&amp;B library on your ...</td>\n",
       "      <td>import Tabs from ‚Äò@theme/Tabs‚Äô;  \\n\\nimport Ta...</td>\n",
       "      <td>{'file_type': '.md', 'language': 'en', 'source...</td>\n",
       "      <td>1291.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The user is getting started with Weights and B...</td>\n",
       "      <td>I need to track my experiment's hyperparameter...</td>\n",
       "      <td>Certainly! You can pass your hyperparameters t...</td>\n",
       "      <td>import Tabs from ‚Äò@theme/Tabs‚Äô;  \\n\\nimport Ta...</td>\n",
       "      <td>{'file_type': '.md', 'language': 'en', 'source...</td>\n",
       "      <td>1291.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A user is trying to do some mathematical opera...</td>\n",
       "      <td>How do I multiply two numbers using W&amp;B functi...</td>\n",
       "      <td>To multiply two numbers, you can use the `numb...</td>\n",
       "      <td>Value\\n\\n\\nWhether the two values are not equ...</td>\n",
       "      <td>{'file_type': '.md', 'language': 'en', 'source...</td>\n",
       "      <td>2186.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A user has been working on making sense of a d...</td>\n",
       "      <td>Hi, I have some confusing numbers that represe...</td>\n",
       "      <td>Yes, there is a function in W&amp;B that allows yo...</td>\n",
       "      <td>Value\\n\\n\\nWhether the two values are not equ...</td>\n",
       "      <td>{'file_type': '.md', 'language': 'en', 'source...</td>\n",
       "      <td>2186.111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  A user has just started using the Weights & Bi...   \n",
       "2  A user has just started using W&B and they are...   \n",
       "4  The user is getting started with Weights and B...   \n",
       "5  A user is trying to do some mathematical opera...   \n",
       "6  A user has been working on making sense of a d...   \n",
       "\n",
       "                                            question  \\\n",
       "0  What is a 'run' in W&B and what can I use it for?   \n",
       "2  Hi! I'm new to W&B and I'm a bit stuck. Can yo...   \n",
       "4  I need to track my experiment's hyperparameter...   \n",
       "5  How do I multiply two numbers using W&B functi...   \n",
       "6  Hi, I have some confusing numbers that represe...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  A 'run' in W&B is the fundamental unit that yo...   \n",
       "2  Sure, you can install the W&B library on your ...   \n",
       "4  Certainly! You can pass your hyperparameters t...   \n",
       "5  To multiply two numbers, you can use the `numb...   \n",
       "6  Yes, there is a function in W&B that allows yo...   \n",
       "\n",
       "                                        page_content  \\\n",
       "0  import Tabs from ‚Äò@theme/Tabs‚Äô;  \\n\\nimport Ta...   \n",
       "2  import Tabs from ‚Äò@theme/Tabs‚Äô;  \\n\\nimport Ta...   \n",
       "4  import Tabs from ‚Äò@theme/Tabs‚Äô;  \\n\\nimport Ta...   \n",
       "5   Value\\n\\n\\nWhether the two values are not equ...   \n",
       "6   Value\\n\\n\\nWhether the two values are not equ...   \n",
       "\n",
       "                                            metadata  context_len  \n",
       "0  {'file_type': '.md', 'language': 'en', 'source...  1291.111111  \n",
       "2  {'file_type': '.md', 'language': 'en', 'source...  1291.111111  \n",
       "4  {'file_type': '.md', 'language': 'en', 'source...  1291.111111  \n",
       "5  {'file_type': '.md', 'language': 'en', 'source...  2186.111111  \n",
       "6  {'file_type': '.md', 'language': 'en', 'source...  2186.111111  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(table.data, columns=table.columns)\n",
    "df = df.dropna()\n",
    "df = df.assign(context_len = lambda df: df.page_content.str.len()/3.6)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d61c89c2-831f-4996-9f07-3965ba839858",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2091"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90391542-9e78-46ea-a197-0bc915f54a44",
   "metadata": {},
   "source": [
    "Let's prepare the training dataset now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dae08b1-5519-43e4-ba28-099950a0bd63",
   "metadata": {},
   "source": [
    "If you use CodeLLama we need to format the instructions accordingly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbb5948d-1b37-46b6-b6e1-5b1c65498bba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "B_INST, E_INST = \"[INST] \", \" [/INST]\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "EOS = \"</s>\"\n",
    "\n",
    "prompt_format = (\n",
    "    B_INST\n",
    "    + B_SYS\n",
    "    + \"You are an AI assistant designed to assist developers with everyday tasks related to Weight & Biases\"\n",
    "    + \"and provide helpful information. As an expert in the open-source python SDK wandb answer the following\"\n",
    "    # + \"question based on the context below. Answer in formatted Markdown.\\n\"\n",
    "    + \"question below. Answer in formatted Markdown.\\n\"\n",
    "    + \"{page_content}\"\n",
    "    + E_SYS\n",
    "    + \"{question}\"\n",
    "    + E_INST\n",
    "    + \"\\n[W&B]\\n\"\n",
    "    + \"{answer}\"\n",
    "    + \"\\n[/W&B]\"\n",
    "    + EOS\n",
    ")\n",
    "\n",
    "def format_text(row):\n",
    "    return prompt_format.format_map(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da903861-dce9-466d-839e-67d937b228e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] <<SYS>>\n",
      "You are an AI assistant designed to assist developers with everyday tasks related to Weight & Biasesand provide helpful information. As an expert in the open-source python SDK wandb answer the followingquestion below. Answer in formatted Markdown.\n",
      "import Tabs from ‚Äò@theme/Tabs‚Äô;  \n",
      "\n",
      "import TabItem from ‚Äò@theme/TabItem‚Äô;\n",
      "\n",
      "\n",
      "# Quickstart\n",
      "\n",
      "\n",
      "Install W&B and start tracking your machine learning experiments in minutes.\n",
      "\n",
      "\n",
      "## 1. Create an account and install W&B\n",
      "\n",
      "\n",
      "Before you get started, make sure you create an account and install W&B:\n",
      "\n",
      "\n",
      "1. Sign up for a free account at <https://wandb.ai/site> and then login to your wandb account.\n",
      "2. Install the wandb library on your machine in a Python 3 environment using `pip`.\n",
      "\n",
      "\n",
      "\n",
      "The following code snippets demonstrate how to install and log into W&B using the W&B CLI and Python Library:\n",
      "\n",
      "\n",
      "\n",
      "Install the CLI and Python library for interacting with the Weights and Biases API:\n",
      "\n",
      "\n",
      "\n",
      "```\n",
      "pip install wandb\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "Install the CLI and Python library for interacting with the Weights and Biases API:\n",
      "\n",
      "\n",
      "\n",
      "```\n",
      "!pip install wandb\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "## 2. Log in to W&B\n",
      "\n",
      "\n",
      "\n",
      "Next, log in to W&B:\n",
      "\n",
      "\n",
      "\n",
      "```\n",
      "wandb login\n",
      "\n",
      "```\n",
      "\n",
      "Or if you are using W&B Server:\n",
      "\n",
      "\n",
      "\n",
      "```\n",
      "wandb login --host=http://wandb.your-shared-local-host.com\n",
      "\n",
      "```\n",
      "\n",
      "Provide your API key when prompted.\n",
      "\n",
      "\n",
      "\n",
      "Next, import the W&B Python SDK and log in:\n",
      "\n",
      "\n",
      "\n",
      "```\n",
      "wandb.login()\n",
      "\n",
      "```\n",
      "\n",
      "Provide your API key when prompted.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## 3. Start a run and track hyperparameters\n",
      "\n",
      "\n",
      "Initialize a W&B Run object in your Python script or notebook with `wandb.init()` and pass a dictionary to the `config` parameter with key-value pairs of hyperparameter names and values:\n",
      "\n",
      "\n",
      "\n",
      "```\n",
      "run = wandb.init(\n",
      "    # Set the project where this run will be logged\n",
      "    project=\"my-awesome-project\",\n",
      "    # Track hyperparameters and run metadata\n",
      "    config={\n",
      "        \"learning_rate\": 0.01,\n",
      "        \"epochs\": 10,\n",
      "    })\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "A run is the basic building block of W&B. You will use them often to track metrics, create logs, create jobs, and more.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## Putting it all together\n",
      "\n",
      "\n",
      "Putting it all together, your training script might look similar to the following code example. The highlighted code shows W&B-specific code.   \n",
      "\n",
      "Note that we added code that mimics machine learning training.\n",
      "\n",
      "\n",
      "\n",
      "```\n",
      "# train.py\n",
      "import wandb\n",
      "import random # for demo script\n",
      "\n",
      "# highlight-next-line\n",
      "wandb.login()\n",
      "\n",
      "epochs=10\n",
      "lr=0.01\n",
      "\n",
      "# highlight-start\n",
      "run = wandb.init(\n",
      "    # Set the project where this run will be logged\n",
      "    project=\"my-awesome-project\",\n",
      "    # Track hyperparameters and run metadata\n",
      "    config={\n",
      "        \"learning_rate\": lr,\n",
      "        \"epochs\": epochs,\n",
      "    })\n",
      "# highlight-end    \n",
      "\n",
      "offset = random.random() / 5\n",
      "print(f\"lr: {lr}\")\n",
      "\n",
      "# simulating a training run\n",
      "for epoch in range(2, epochs):\n",
      "    acc = 1 - 2 ** -epoch - random.random() / epoch - offset\n",
      "    loss = 2 ** -epoch + random.random() / epoch + offset\n",
      "    print(f\"epoch={epoch}, accuracy={acc}, loss={loss}\")\n",
      "    # highlight-next-line\n",
      "    wandb.log({\"accuracy\": acc, \"loss\": loss})\n",
      "\n",
      "# run.log_code()\n",
      "\n",
      "```\n",
      "\n",
      "That‚Äôs it! Navigate to the W&B App at <https://wandb.ai/home> to view how the metrics we logged with W&B (accuracy and loss) improved during each training step.\n",
      "\n",
      "\n",
      "\n",
      "The image above (click to expand) shows the loss and accuracy that was tracked from each time we ran the script above. Each run object that was created is show within the **Runs** column. Each run name is randomly generated.\n",
      "\n",
      "\n",
      "## What‚Äôs next?\n",
      "\n",
      "\n",
      "\n",
      "Explore the rest of the W&B ecosystem.\n",
      "\n",
      "\n",
      "1. Check out W&B Integrations to learn how to integrate W&B with your ML framework such as PyTorch, ML library such as Hugging Face, or ML service such as SageMaker.\n",
      "2. Organize runs, embed and automate visualizations, describe your findings, and share updates with collaborators with W&B Reports.\n",
      "3. Create W&B Artifacts to track datasets, models, dependencies, and results through each step of your machine learning pipeline.\n",
      "4. Automate hyperparameter search and explore the space of possible models with W&B Sweeps.\n",
      "5. Understand your datasets, visualize model predictions, and share insights in a central dashboard.\n",
      "\n",
      "\n",
      "\n",
      "## Common Questions\n",
      "\n",
      "\n",
      "**Where do I find my API key?**  \n",
      "\n",
      "Once you‚Äôve signed in to www.wandb.ai, the API key will be on the Authorize page.\n",
      "\n",
      "\n",
      "**How do I use W&B in an automated environment?**  \n",
      "\n",
      "If you are training models in an automated environment where it‚Äôs inconvenient to run shell commands, such as Google‚Äôs CloudML, you should look at our guide to configuration with Environment Variables.\n",
      "\n",
      "\n",
      "**Do you offer local, on-prem installs?**  \n",
      "\n",
      "Yes, you can privately host W&B locally on your own machines or in a private cloud, try this quick tutorial notebook to see how. Note, to login to wandb local server you can set the host flag to the address of the local instance. \n",
      "\n",
      "\n",
      "**How do I turn off wandb logging temporarily?**  \n",
      "\n",
      "If are testing code and want to disable wandb syncing, set the environment variable `WANDB_MODE=offline`.\n",
      "\n",
      "\n",
      "<</SYS>>\n",
      "\n",
      "What is a 'run' in W&B and what can I use it for? [/INST]\n",
      "[W&B]\n",
      "A 'run' in W&B is the fundamental unit that you can use to track various aspects of your machine learning experiments. Once you initialize a W&B Run object in your Python script or notebook using `wandb.init()`, you can pass a dictionary to the `config` parameter where the key-value pairs are your hyperparameters with their corresponding values. You can use a 'run' to track metrics, create logs, jobs and do many more things.\n",
      "[/W&B]</s>\n"
     ]
    }
   ],
   "source": [
    "one_example = format_text(df.iloc[0])\n",
    "print(one_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf19de4-c29a-4803-aad1-8eb0b9c32da5",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's compute the format over all the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "369e92cb-d51d-4f97-93e0-bb3c709eb126",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"text\"] = df.apply(format_text, axis=1)\n",
    "\n",
    "# print(df.iloc[200][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c18f6fe4-6573-4901-ac44-aa51d0400452",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_json(\"wandb_questions_ds.jsonl\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01efd5c0-1fec-4c76-bd6e-1ab182deb7c3",
   "metadata": {},
   "source": [
    "## Saving your work to W&B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3867767-df18-4866-9c78-ca623ad9b205",
   "metadata": {},
   "source": [
    "We should log this to W&B so we can inspect the dataset interactively using W&B Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "902581de-ada6-44c4-b399-ef24845948e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">efficient-salad-36</strong> at: <a href='https://wandb.ai/capecape/aws_llm_demo/runs/cp1x98ab' target=\"_blank\">https://wandb.ai/capecape/aws_llm_demo/runs/cp1x98ab</a><br/>Synced 7 W&B file(s), 1 media file(s), 1 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231017_101155-cp1x98ab/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table = wandb.Table(dataframe=df)\n",
    "wandb.log({\"wandb_questions_ds\": table})\n",
    "\n",
    "# let's also save a the dataset at this stage\n",
    "at = wandb.Artifact(\n",
    "    name=\"wandb_questions_ds\", \n",
    "    type=\"dataset\",\n",
    "    description=\"A wandbot dataset of questions and answers about W&B for training (non tokenized)\",\n",
    "    metadata={\"prompt_format\": prompt_format,\n",
    "              \"length\": len(df),\n",
    "             }\n",
    ")\n",
    "at.add_file(\"wandb_questions_ds.jsonl\")\n",
    "wandb.log_artifact(at)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdebe295-f927-406f-b790-27bc059abab1",
   "metadata": {},
   "source": [
    "## Tokenizing and saving the preprocessing\n",
    "We can save time during training by pre-processing the dataset and loading directly a tokenized dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5380e7bd-66f3-4237-a901-fe935a249982",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"codellama/CodeLlama-7b-Instruct-hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20aaffb3-d181-4c34-a58d-3e9c78a16d14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:655: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_auth_token=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03ed5fc-a178-424d-8bc5-56f452dc3487",
   "metadata": {},
   "source": [
    "we can convert the data to a huggingface parquet-based dataset for fast loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33ad3e77-c60c-46a1-9fef-432d412bccc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/sagemaker-llama2-wandb/training/wandb/run-20231017_101247-xsdwirw4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/capecape/aws_llm_demo/runs/xsdwirw4' target=\"_blank\">gentle-resonance-37</a></strong> to <a href='https://wandb.ai/capecape/aws_llm_demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/capecape/aws_llm_demo' target=\"_blank\">https://wandb.ai/capecape/aws_llm_demo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/capecape/aws_llm_demo/runs/xsdwirw4' target=\"_blank\">https://wandb.ai/capecape/aws_llm_demo/runs/xsdwirw4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "wandb.init(project=WANDB_PROJECT, job_type=\"tokenizing\")\n",
    "artifact = wandb.use_artifact('capecape/aws_llm_demo/wandb_questions_ds:v2', type='dataset')\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d894909-a161-4806-832f-0da72a580860",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['context', 'question', 'answer', 'page_content', 'metadata', 'context_len', 'text'],\n",
       "    num_rows: 2091\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = load_dataset(\n",
    "    path=\".\", \n",
    "    data_files=f\"{artifact_dir}/wandb_questions_ds.jsonl\", \n",
    "    split=\"train\")\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676fbde0-d780-4beb-94dd-fff1a5a617ac",
   "metadata": {},
   "source": [
    "one sample looks like this üëá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a4aa0e2-c9b3-4065-8c4a-ca24f8bfd856",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.select_columns([\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5df85d-be1f-4726-92c8-73e94146ea5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Packing and chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac52401-ea01-44bb-95d7-b11f8aa34b59",
   "metadata": {},
   "source": [
    "We define some helper functions to pack our samples into sequences of a given length and then tokenize them.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0eb36f2-6dbf-4f13-b8ea-1ba2effc709c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a57caae2e1c42dbbda8ad4e3ed0b7f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2091 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '[INST] <<SYS>>\\nYou are an AI assistant designed to assist developers with everyday tasks related to Weight & Biasesand provide helpful information. As an expert in the open-source python SDK wandb answer the followingquestion below. Answer in formatted Markdown.\\n torchvision==0.9.2 torchaudio==0.8.2 --extra-index-url https://download.pytorch.org/whl/lts/1.8/cu111\\n# Download a util file of helper methods for this notebook\\n!curl https://raw.githubusercontent.com/staceysv/dsviz-demo/master/util.py --output util.py\\n\\n```\\n\\n\\n```\\n# Colab sometimes has problems with Pillow. If you are facing this issue, \\n# uncomment the `exit()` line and run this cell. Then rerun the `!pip install`\\n# cell above.\\n\\n# exit()\\n\\n```\\n\\n\\n```\\nimport util\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport os\\nfrom PIL import Image\\nimport shutil\\nimport wandb\\nprint(wandb.__version__)\\n\\n```\\n\\n## Login to wandb\\n\\n\\n\\n```\\n# default project name where results will be logged\\nWANDB_PROJECT = \"dsviz-demo\"\\n\\n```\\n\\n\\n```\\nwandb.login()\\n\\n```\\n\\n\\n```\\n# set SIZE to \"TINY\", \"MEDIUM\" or (read the warning) \"LARGE\"\\n# to select one of these datasets\\n# TINY dataset: 50 images\\n# MEDIUM dataset: 200 images\\n# warning: you may run out of RAM in Colab & need to restart the notebook\\n# between steps at this size\\n# LARGE dataset: 400 images \\n\\nSIZE = \"TINY\"\\nPREFIX = \"bdd\"\\n\\nif SIZE == \"TINY\":\\n  NUM_EXAMPLES = 50\\n  SPLITS = {\"train\" : 40, \"test\" : 10}\\nelif SIZE == \"MEDIUM\":\\n  NUM_EXAMPLES = 200\\n  SPLITS = {\"train\" : 160, \"test\" : 40}\\nelif SIZE == \"LARGE\": \\n  NUM_EXAMPLES = 400\\n  SPLITS = {\"train\" : 320, \"test\" : 80}\\n\\n# set globals\\nIMAGE_ROOT = \"segment_demo/images/train\"\\nLABEL_ROOT = \"segment_demo/labels/train\"\\n\\n# set global Artifact names (allowing steps to be rerun independently)\\nRAW_DATA_AT = \"_\".join([PREFIX, \"raw_data\", str(NUM_EXAMPLES)])\\nTRAIN_DATA_AT = \"_\".join([PREFIX, \"train_data\", str(NUM_EXAMPLES)])\\nTEST_DATA_AT = \"_\".join([PREFIX, \"test_data\", str(NUM_EXAMPLES)])\\n\\n```\\n\\n## Download the data\\n\\n\\nBefore we get started, we will download an example dataset to our local machine. This is a big dataset (958MB) so please be patient if you are on a slow connection. For brevity, we put utility functions for working with the dataset in `util.py`. After the download is complete, we will show an example of the data.\\n\\n\\n**Note:** if you see the error ‚Äú`AttributeError: module \\'PIL.TiffTags\\' has no attribute \\'IFD\\'`‚Äù, this is likely a Colab issue which can be solved by restarting your runtime (header menu > Runtime > Restart runtime).\\n\\n\\n\\n```\\n# Download the training data: this is a subset of the Berkeley Deep Drive 100K dataset,\\n# which is available at https://bdd-data.berkeley.edu/ \\n!curl -SL -qq https://storage.googleapis.com/wandb_datasets/BDD100K_seg_demo.zip > BDD100K_seg_demo.zip\\n!unzip -qq BDD100K_seg_demo.zip\\n\\n# Print the label types:\\nprint(\"Class Mapping:\")\\nprint(list(zip(util.BDD_IDS, util.BDD_CLASSES)))\\n\\n```\\n\\n\\n```\\n# Show some example training images\\nsamples = [\"0004a4c0-d4dff0ad\", \"00067cfb-e535423e\", \"0010bf16-a457685b\", \"001b428f-059bac33\"]\\nfor sample_id in samples:\\n  # raw image\\n  util.show_image(\"segment_demo/images/train/{}.jpg\".format(sample_id))\\n  # corresponding color label mask\\n  util.show_image(\"segment_demo/labels/train/{}_train_id.png\".format(sample_id))\\n\\n```\\n\\n# Step 1: Build the dataset\\n\\n\\nFirst, let‚Äôs build a dataset for use in the rest of this project using a `wandb.Run`. A `Run` is an isolated process which can optionally depend on upstream artifacts as well as optionally produce artifacts for later consumption. In this step, we will create a `wandb.Table` during our run and output it in an artifact. This table will contain all of our raw data for later use. W&B also offers rich tools to analyze and visualize such Tables in an interactive UI.\\n\\n\\nSee a live example of the raw dataset in W&B\\n\\n\\n\\n```\\nfrom PIL import Image\\n\\n# Initialize the run\\nrun = wandb.init(project=WANDB_PROJECT,\\n                 job_type=\"upload\",\\n                 config={\\n                     \"num_examples\" : NUM_EXAMPLES,\\n                     \"num_train\" : SPLITS[\"train\"],\\n                     \"num_test\" : SPLITS[\"test\"]\\n                 })\\n\\n# Setup a WandB Classes object. This will give additional metadata for visuals\\nclass_set = wandb.Classes([{\\'name\\': name, \\'id\\': id} \\n                           for name, id in zip(util.BDD_CLASSES, util.BDD_IDS)])\\n\\n# Create an Artifact (versioned folder)\\nartifact = wandb.Artifact(name=RAW_DATA_AT, type=\"raw_data\")\\n\\n# Setup a WandB Table object to hold our dataset\\ncolumns=[\"id\", \"raw\", \"annotated\", \"color_mask\", \"raw_label\"]\\n# add a column for the pixel fraction of each class label\\ncolumns.extend([\"%_\" + c for c in util.BDD_CLASSES])\\ntable = wandb.Table(\\n    columns=columns\\n)\\n\\n# temporary directory to hold intermediate visualizations\\nTMPDIR = \"tmp_labels\"\\nif not os.path.isdir(TMPDIR):\\n  os.mkdir(TMPDIR)\\n\\n# Fill up the table\\nall_images = [f for f in os.listdir(IMAGE_ROOT)]\\nfor ndx in range(wandb.config.num_examples):\\n  img = all_images[ndx]\\n  img_file = os.path.join(IMAGE_ROOT, img)\\n  train_id = img.split(\".\")[0]\\n  label_file = os.path.join(LABEL_ROOT, train_id + \"_train_id.png\")\\n\\n  # First, we will build a wandb.Image to act as our raw example object\\n  #    classes: the classes which map to masks and/or box metadata\\n  #    masks: the mask metadata. In this case, we use a 2d array w\\n  #           here each cell corresponds to the label (this comes directly from the dataset)\\n  raw_img = wandb.Image(img_file)\\n  annotated = wandb.Image(img_file, classes=class_set,\\n                        masks={\"ground_truth\" : {\"mask_data\": np.array(Image.open(label_file))}})\\n\\n  # Next, we create an additional image which may be helpful during analysis\\n  # and compute the fraction of each image covered by each of the classes\\n  # (so we can find examples with more pixels of cars vs pedestrians vs other\\n  # classes of interest). This additional metadata is optional\\n  color_mask = util.static_label(label_file, train_id)\\n  class_fractions = util.count_pixels(label_file)\\n  raw_label = wandb.Image(label_file)\\n\\n  # use .add_file for the files we need to reference by path\\n  # (in this case the training image and the label)\\n  artifact.add_file(img_file, os.path.join(\"images\", img))\\n  artifact.add_file(label_file, os.path.join(\"labels\", train_id + \"_train_id.png\"))\\n\\n  # Finally, we add a row of our newly constructed data.\\n  row = [train_id, raw_img, annotated, color_mask, raw_label]\\n  row.extend(class_fractions)\\n  table.add_data(*row)\\n\\n# .add the table to the artifact\\nartifact.add(table, \"raw_examples\")\\n\\n# Finally, log the artifact\\nprint(\"Saving data to WandB...\")\\nrun.log_artifact(artifact)\\nrun.finish()\\nprint(\"... Run Complete\")\\n\\n# clear out the temporary files \\nshutil.rmtree(TMPDIR)\\n\\n```\\n\\n### Review the dataset in the Dashboard\\n\\n\\nGreat, now if you click on the URL above, you should land on a run page. Since we did not log any metrics, there are no charts. Click the database icon (it looks like a stack of hockey pucks) on the left panel to see this run‚Äôs artifacts. You should see something similar to the following:\\n\\n\\n\\nClick on the ‚Äú`raw_data`‚Äù row to see an Oveview page like this:\\n\\n\\n\\nClicking on the ‚Äú`raw\\\\_examples‚Äù entry under Tables will launch an interactive data explorer to review the table we just built. Here I‚Äôve advanced to a page where you can see some humans.\\n\\n\\n\\nYou can also access this table as a json file under the ‚ÄúFiles‚Äù tab, which lists all the files stored in this Artifact.  \\n\\n\\n\\n\\n# Step 2: Splitting the data into train and test\\n\\n\\nNext, we will split the data into a train and a test dataset. Similar to before, we will launch a `Run` to perform this operation. Remember, this new execution could happen on a different machine as we will dynamically load the needed resources. In particular, we will load in the raw dataset from the last run and split it into 2 new datasets.\\n\\n\\nSee live examples of the train data and test data artifacts in W&B.\\n\\n\\n\\n```\\n# Initialize a run (you can use the job_type to better organize runs)\\nrun = wandb.init(project=WANDB_PROJECT, job_type=\"data_split\")\\n\\n# Get the latest version of the artifact. \\n# Notice the name alias follows this convention: \"<ARTIFACT_NAME>:<VERSION>\"\\n# When version is set to \"latest\", then the latest version will always be used.\\n# However, you can pin to\\n<</SYS>>\\n\\nHow can I start a new run to split my raw data into train and test sets in Weights & Biases? [/INST]\\n[W&B]\\nYou can initialize a new run for splitting your data in W&B using the `wandb.init()` function. This function creates a new execution of a run that is tracked by W&B. You can specify the project and job type as arguments in this function.\\nFor instance:\\n```\\nrun = wandb.init(project=WANDB_PROJECT, job_type=\"data_split\")\\n```\\nIn this example, `WANDB_PROJECT` is the project name and `data_split` is the job type that indicates that this run is for splitting your raw data into training and testing datasets.\\n[/W&B]</s>'}</s>\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "# template dataset to add prompt to each sample\n",
    "def template_dataset(sample):\n",
    "    sample[\"text\"] = f\"{sample}{tokenizer.eos_token}\"\n",
    "    return sample\n",
    "\n",
    "\n",
    "# apply prompt template per sample\n",
    "train_dataset = train_dataset.map(template_dataset)\n",
    "# print random sample\n",
    "print(train_dataset[randint(0, len(train_dataset))][\"text\"])\n",
    "\n",
    "# empty list to save remainder from batches to use in next batch\n",
    "remainder = {\"input_ids\": [], \"attention_mask\": [], \"token_type_ids\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec8e2766-5b3a-4424-82e6-1cf5ef45da1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e753ba791e4798bfbf0e006ed41199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2091 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f0742e55cbe443687e7724650239b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2091 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 4906\n"
     ]
    }
   ],
   "source": [
    "def chunk(sample, chunk_length=1024):\n",
    "    # define global remainder variable to save remainder from batches to use in next batch\n",
    "    global remainder\n",
    "    # Concatenate all texts and add remainder from previous batch\n",
    "    concatenated_examples = {k: list(chain(*sample[k])) for k in sample.keys()}\n",
    "    concatenated_examples = {k: remainder[k] + concatenated_examples[k] for k in concatenated_examples.keys()}\n",
    "    # get total number of tokens for batch\n",
    "    batch_total_length = len(concatenated_examples[list(sample.keys())[0]])\n",
    "\n",
    "    # get max number of chunks for batch\n",
    "    if batch_total_length >= chunk_length:\n",
    "        batch_chunk_length = (batch_total_length // chunk_length) * chunk_length\n",
    "\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + chunk_length] for i in range(0, batch_chunk_length, chunk_length)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    # add remainder to global variable for next batch\n",
    "    remainder = {k: concatenated_examples[k][batch_chunk_length:] for k in concatenated_examples.keys()}\n",
    "    # prepare labels\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "\n",
    "# tokenize and chunk dataset\n",
    "lm_dataset = train_dataset.map(\n",
    "    lambda sample: tokenizer(sample[\"text\"]), batched=True, remove_columns=list(train_dataset.features)\n",
    ").map(\n",
    "    partial(chunk, chunk_length=1024),\n",
    "    batched=True,\n",
    ")\n",
    "\n",
    "# Print total number of samples\n",
    "print(f\"Total number of samples: {len(lm_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd4726a-5381-4a56-8e5a-59fdfffb8c7c",
   "metadata": {},
   "source": [
    "## Save to a bucket and W&B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb0ecae-ed90-4f83-a34d-99e46daa4d1b",
   "metadata": {},
   "source": [
    "We are now going to use W&B Aritfacts integration with S3 buckets, so our dataset is close to the training compute SM instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "322268d9-80a8-4f67-bf55-76cf4773ca95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b16400d9b14423a80e8b82ab51564cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4906 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded data to:\n",
      "training dataset to: s3://sagemaker-us-east-1-372108735839/processed/wandbot/train\n"
     ]
    }
   ],
   "source": [
    "# save train_dataset to s3\n",
    "if USE_S3:\n",
    "    training_input_path = f's3://{sess.default_bucket()}/processed/wandbot/train'\n",
    "else:\n",
    "    training_input_path = \"./wandbot_train_ds\"\n",
    "\n",
    "lm_dataset.save_to_disk(training_input_path)\n",
    "\n",
    "print(\"uploaded data to:\")\n",
    "print(f\"training dataset to: {training_input_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f92d3c9a-f01d-4b6e-8a20-ab707918a0e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "at = wandb.Artifact(\n",
    "    name=\"wandbot_dataset\", \n",
    "    type=\"dataset\",\n",
    "    description=\"A wandbot dataset of questions and answers about W&B - CodeLLama tokenized\",\n",
    "    metadata={\"model_name\": MODEL_NAME, \"tokenizer\": MODEL_NAME},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7edcf658-cd05-46de-bc30-45c27a8f4853",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Generating checksum for up to 10000 objects in \"sagemaker-us-east-1-372108735839/processed/wandbot/train\"... Done. 0.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Artifact wandbot_dataset>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if USE_S3:\n",
    "    at.add_reference(training_input_path)\n",
    "else:\n",
    "    at.add_dir(training_input_path)\n",
    "wandb.log_artifact(at)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbd2e08-939d-4269-8d65-8ae3684fb3de",
   "metadata": {},
   "source": [
    "Let's finish this run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c3900fa-e7b2-4b59-be6f-d9d2459e237c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd5d786743834847b9720d87a3b45ec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.386 MB of 0.386 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">gentle-resonance-37</strong> at: <a href='https://wandb.ai/capecape/aws_llm_demo/runs/xsdwirw4' target=\"_blank\">https://wandb.ai/capecape/aws_llm_demo/runs/xsdwirw4</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231017_101247-xsdwirw4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b63367-19f7-4bb6-b2f8-44e200c74df6",
   "metadata": {},
   "source": [
    "# Eval Dataset\n",
    "We prepared a set of questions from the bot that were gathered and curated by my colleague Ayush T."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d607bff-cbbd-4554-822f-a0fbabe0c659",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import wandb\n",
    "\n",
    "api = wandb.Api()\n",
    "question_artifacts = api.artifact(\"wandbot/wandbot-eval/run-kinbxic4-responses:v0\")\n",
    "\n",
    "with open(question_artifacts.file()) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "columns = data[\"columns\"]\n",
    "data = data[\"data\"]\n",
    "eval_df = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c78e291-ce2d-4061-9720-71f8bdf317ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>retrieved_context</th>\n",
       "      <th>generated_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hey I have a question about using wandb with f...</td>\n",
       "      <td>[`wandb.init()` returns a run object, and you ...</td>\n",
       "      <td>The initialization of `wandb.init()` should be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey with wandb is it possible to link from the...</td>\n",
       "      <td>[### How do I best log models from runs in a s...</td>\n",
       "      <td>Yes, you can link to the best run from a sweep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am training a spacy textcat model. This proc...</td>\n",
       "      <td>[### Model Architecture\\n\\nOur config also def...</td>\n",
       "      <td>To log the best model's metrics instead of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Explain how I can version datasets with Weight...</td>\n",
       "      <td>[ # A 3-in-1 Intro to Weights &amp; Biases: Comput...</td>\n",
       "      <td>Weights &amp; Biases provides a feature called Art...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm using   env = SubprocVecEnv(\\n        [mak...</td>\n",
       "      <td>[## WandbCallback ÂºïÊï∞\\n\\n| ÂºïÊï∞ | ‰ΩøÁî®Ê≥ï | | --- | -...</td>\n",
       "      <td>To record a video for a specific subprocess en...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Hey I have a question about using wandb with f...   \n",
       "1  Hey with wandb is it possible to link from the...   \n",
       "2  I am training a spacy textcat model. This proc...   \n",
       "3  Explain how I can version datasets with Weight...   \n",
       "4  I'm using   env = SubprocVecEnv(\\n        [mak...   \n",
       "\n",
       "                                   retrieved_context  \\\n",
       "0  [`wandb.init()` returns a run object, and you ...   \n",
       "1  [### How do I best log models from runs in a s...   \n",
       "2  [### Model Architecture\\n\\nOur config also def...   \n",
       "3  [ # A 3-in-1 Intro to Weights & Biases: Comput...   \n",
       "4  [## WandbCallback ÂºïÊï∞\\n\\n| ÂºïÊï∞ | ‰ΩøÁî®Ê≥ï | | --- | -...   \n",
       "\n",
       "                                  generated_response  \n",
       "0  The initialization of `wandb.init()` should be...  \n",
       "1  Yes, you can link to the best run from a sweep...  \n",
       "2  To log the best model's metrics instead of the...  \n",
       "3  Weights & Biases provides a feature called Art...  \n",
       "4  To record a video for a specific subprocess en...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb58d1b-0b17-49e3-8768-b9baeb3d9046",
   "metadata": {},
   "source": [
    "Let's remove retrieved Japanese text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646a2941-5ea9-47be-98e2-8731387f6114",
   "metadata": {
    "tags": []
   },
   "source": [
    "### clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fee50101-b6a7-4e08-ab2f-e426b5e9840c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def contains_japanese(text):\n",
    "    for char in text:\n",
    "        if '‰∏Ä' <= char <= 'Èæ•':\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "365bff6a-c0bc-4765-8044-854df497d29b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s = \"## WandbCallback ÂºïÊï∞\\n\\n| ÂºïÊï∞ | ‰ΩøÁî®Ê≥ï |\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "addabb0a-5569-4c26-9b29-17484a20832d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_df[\"retrieved_context_en\"] = [[ctx for ctx in ctxs if not contains_japanese(ctx)] for ctxs in eval_df.retrieved_context.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd18bd4e-aeb5-4ac7-a547-08252188b048",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>retrieved_context</th>\n",
       "      <th>generated_response</th>\n",
       "      <th>retrieved_context_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hey I have a question about using wandb with f...</td>\n",
       "      <td>[`wandb.init()` returns a run object, and you ...</td>\n",
       "      <td>The initialization of `wandb.init()` should be...</td>\n",
       "      <td>[`wandb.init()` returns a run object, and you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey with wandb is it possible to link from the...</td>\n",
       "      <td>[### How do I best log models from runs in a s...</td>\n",
       "      <td>Yes, you can link to the best run from a sweep...</td>\n",
       "      <td>[### How do I best log models from runs in a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am training a spacy textcat model. This proc...</td>\n",
       "      <td>[### Model Architecture\\n\\nOur config also def...</td>\n",
       "      <td>To log the best model's metrics instead of the...</td>\n",
       "      <td>[### Model Architecture\\n\\nOur config also def...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Explain how I can version datasets with Weight...</td>\n",
       "      <td>[ # A 3-in-1 Intro to Weights &amp; Biases: Comput...</td>\n",
       "      <td>Weights &amp; Biases provides a feature called Art...</td>\n",
       "      <td>[ # A 3-in-1 Intro to Weights &amp; Biases: Comput...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm using   env = SubprocVecEnv(\\n        [mak...</td>\n",
       "      <td>[## WandbCallback ÂºïÊï∞\\n\\n| ÂºïÊï∞ | ‰ΩøÁî®Ê≥ï | | --- | -...</td>\n",
       "      <td>To record a video for a specific subprocess en...</td>\n",
       "      <td>[## Basic Example\\n\\nThe W&amp;B SB3 integration u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Hey I have a question about using wandb with f...   \n",
       "1  Hey with wandb is it possible to link from the...   \n",
       "2  I am training a spacy textcat model. This proc...   \n",
       "3  Explain how I can version datasets with Weight...   \n",
       "4  I'm using   env = SubprocVecEnv(\\n        [mak...   \n",
       "\n",
       "                                   retrieved_context  \\\n",
       "0  [`wandb.init()` returns a run object, and you ...   \n",
       "1  [### How do I best log models from runs in a s...   \n",
       "2  [### Model Architecture\\n\\nOur config also def...   \n",
       "3  [ # A 3-in-1 Intro to Weights & Biases: Comput...   \n",
       "4  [## WandbCallback ÂºïÊï∞\\n\\n| ÂºïÊï∞ | ‰ΩøÁî®Ê≥ï | | --- | -...   \n",
       "\n",
       "                                  generated_response  \\\n",
       "0  The initialization of `wandb.init()` should be...   \n",
       "1  Yes, you can link to the best run from a sweep...   \n",
       "2  To log the best model's metrics instead of the...   \n",
       "3  Weights & Biases provides a feature called Art...   \n",
       "4  To record a video for a specific subprocess en...   \n",
       "\n",
       "                                retrieved_context_en  \n",
       "0  [`wandb.init()` returns a run object, and you ...  \n",
       "1  [### How do I best log models from runs in a s...  \n",
       "2  [### Model Architecture\\n\\nOur config also def...  \n",
       "3  [ # A 3-in-1 Intro to Weights & Biases: Comput...  \n",
       "4  [## Basic Example\\n\\nThe W&B SB3 integration u...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12b8732a-e42e-4f19-b8ee-baceb673f32d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_df[\"retrieved_context_stuff\"] = [\"\\n\".join(ctxs) for ctxs in eval_df.retrieved_context_en.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14459a92-98fe-4674-9e8a-7afdaf7c1095",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>retrieved_context</th>\n",
       "      <th>generated_response</th>\n",
       "      <th>retrieved_context_en</th>\n",
       "      <th>retrieved_context_stuff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hey I have a question about using wandb with f...</td>\n",
       "      <td>[`wandb.init()` returns a run object, and you ...</td>\n",
       "      <td>The initialization of `wandb.init()` should be...</td>\n",
       "      <td>[`wandb.init()` returns a run object, and you ...</td>\n",
       "      <td>`wandb.init()` returns a run object, and you c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey with wandb is it possible to link from the...</td>\n",
       "      <td>[### How do I best log models from runs in a s...</td>\n",
       "      <td>Yes, you can link to the best run from a sweep...</td>\n",
       "      <td>[### How do I best log models from runs in a s...</td>\n",
       "      <td>### How do I best log models from runs in a sw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am training a spacy textcat model. This proc...</td>\n",
       "      <td>[### Model Architecture\\n\\nOur config also def...</td>\n",
       "      <td>To log the best model's metrics instead of the...</td>\n",
       "      <td>[### Model Architecture\\n\\nOur config also def...</td>\n",
       "      <td>### Model Architecture\\n\\nOur config also defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Explain how I can version datasets with Weight...</td>\n",
       "      <td>[ # A 3-in-1 Intro to Weights &amp; Biases: Comput...</td>\n",
       "      <td>Weights &amp; Biases provides a feature called Art...</td>\n",
       "      <td>[ # A 3-in-1 Intro to Weights &amp; Biases: Comput...</td>\n",
       "      <td># A 3-in-1 Intro to Weights &amp; Biases: Compute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm using   env = SubprocVecEnv(\\n        [mak...</td>\n",
       "      <td>[## WandbCallback ÂºïÊï∞\\n\\n| ÂºïÊï∞ | ‰ΩøÁî®Ê≥ï | | --- | -...</td>\n",
       "      <td>To record a video for a specific subprocess en...</td>\n",
       "      <td>[## Basic Example\\n\\nThe W&amp;B SB3 integration u...</td>\n",
       "      <td>## Basic Example\\n\\nThe W&amp;B SB3 integration us...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Hey I have a question about using wandb with f...   \n",
       "1  Hey with wandb is it possible to link from the...   \n",
       "2  I am training a spacy textcat model. This proc...   \n",
       "3  Explain how I can version datasets with Weight...   \n",
       "4  I'm using   env = SubprocVecEnv(\\n        [mak...   \n",
       "\n",
       "                                   retrieved_context  \\\n",
       "0  [`wandb.init()` returns a run object, and you ...   \n",
       "1  [### How do I best log models from runs in a s...   \n",
       "2  [### Model Architecture\\n\\nOur config also def...   \n",
       "3  [ # A 3-in-1 Intro to Weights & Biases: Comput...   \n",
       "4  [## WandbCallback ÂºïÊï∞\\n\\n| ÂºïÊï∞ | ‰ΩøÁî®Ê≥ï | | --- | -...   \n",
       "\n",
       "                                  generated_response  \\\n",
       "0  The initialization of `wandb.init()` should be...   \n",
       "1  Yes, you can link to the best run from a sweep...   \n",
       "2  To log the best model's metrics instead of the...   \n",
       "3  Weights & Biases provides a feature called Art...   \n",
       "4  To record a video for a specific subprocess en...   \n",
       "\n",
       "                                retrieved_context_en  \\\n",
       "0  [`wandb.init()` returns a run object, and you ...   \n",
       "1  [### How do I best log models from runs in a s...   \n",
       "2  [### Model Architecture\\n\\nOur config also def...   \n",
       "3  [ # A 3-in-1 Intro to Weights & Biases: Comput...   \n",
       "4  [## Basic Example\\n\\nThe W&B SB3 integration u...   \n",
       "\n",
       "                             retrieved_context_stuff  \n",
       "0  `wandb.init()` returns a run object, and you c...  \n",
       "1  ### How do I best log models from runs in a sw...  \n",
       "2  ### Model Architecture\\n\\nOur config also defi...  \n",
       "3   # A 3-in-1 Intro to Weights & Biases: Compute...  \n",
       "4  ## Basic Example\\n\\nThe W&B SB3 integration us...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61dd549f-1923-4e81-ba84-a5fa5dcbb297",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_df = eval_df.assign(tokens = eval_df['retrieved_context_stuff'].str.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a37a312e-08cf-4406-99d5-87342709dcc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>retrieved_context</th>\n",
       "      <th>generated_response</th>\n",
       "      <th>retrieved_context_en</th>\n",
       "      <th>retrieved_context_stuff</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hey I have a question about using wandb with f...</td>\n",
       "      <td>[`wandb.init()` returns a run object, and you ...</td>\n",
       "      <td>The initialization of `wandb.init()` should be...</td>\n",
       "      <td>[`wandb.init()` returns a run object, and you ...</td>\n",
       "      <td>`wandb.init()` returns a run object, and you c...</td>\n",
       "      <td>15505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey with wandb is it possible to link from the...</td>\n",
       "      <td>[### How do I best log models from runs in a s...</td>\n",
       "      <td>Yes, you can link to the best run from a sweep...</td>\n",
       "      <td>[### How do I best log models from runs in a s...</td>\n",
       "      <td>### How do I best log models from runs in a sw...</td>\n",
       "      <td>13161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am training a spacy textcat model. This proc...</td>\n",
       "      <td>[### Model Architecture\\n\\nOur config also def...</td>\n",
       "      <td>To log the best model's metrics instead of the...</td>\n",
       "      <td>[### Model Architecture\\n\\nOur config also def...</td>\n",
       "      <td>### Model Architecture\\n\\nOur config also defi...</td>\n",
       "      <td>17812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Explain how I can version datasets with Weight...</td>\n",
       "      <td>[ # A 3-in-1 Intro to Weights &amp; Biases: Comput...</td>\n",
       "      <td>Weights &amp; Biases provides a feature called Art...</td>\n",
       "      <td>[ # A 3-in-1 Intro to Weights &amp; Biases: Comput...</td>\n",
       "      <td># A 3-in-1 Intro to Weights &amp; Biases: Compute...</td>\n",
       "      <td>12755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm using   env = SubprocVecEnv(\\n        [mak...</td>\n",
       "      <td>[## WandbCallback ÂºïÊï∞\\n\\n| ÂºïÊï∞ | ‰ΩøÁî®Ê≥ï | | --- | -...</td>\n",
       "      <td>To record a video for a specific subprocess en...</td>\n",
       "      <td>[## Basic Example\\n\\nThe W&amp;B SB3 integration u...</td>\n",
       "      <td>## Basic Example\\n\\nThe W&amp;B SB3 integration us...</td>\n",
       "      <td>15480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Hey I have a question about using wandb with f...   \n",
       "1  Hey with wandb is it possible to link from the...   \n",
       "2  I am training a spacy textcat model. This proc...   \n",
       "3  Explain how I can version datasets with Weight...   \n",
       "4  I'm using   env = SubprocVecEnv(\\n        [mak...   \n",
       "\n",
       "                                   retrieved_context  \\\n",
       "0  [`wandb.init()` returns a run object, and you ...   \n",
       "1  [### How do I best log models from runs in a s...   \n",
       "2  [### Model Architecture\\n\\nOur config also def...   \n",
       "3  [ # A 3-in-1 Intro to Weights & Biases: Comput...   \n",
       "4  [## WandbCallback ÂºïÊï∞\\n\\n| ÂºïÊï∞ | ‰ΩøÁî®Ê≥ï | | --- | -...   \n",
       "\n",
       "                                  generated_response  \\\n",
       "0  The initialization of `wandb.init()` should be...   \n",
       "1  Yes, you can link to the best run from a sweep...   \n",
       "2  To log the best model's metrics instead of the...   \n",
       "3  Weights & Biases provides a feature called Art...   \n",
       "4  To record a video for a specific subprocess en...   \n",
       "\n",
       "                                retrieved_context_en  \\\n",
       "0  [`wandb.init()` returns a run object, and you ...   \n",
       "1  [### How do I best log models from runs in a s...   \n",
       "2  [### Model Architecture\\n\\nOur config also def...   \n",
       "3  [ # A 3-in-1 Intro to Weights & Biases: Comput...   \n",
       "4  [## Basic Example\\n\\nThe W&B SB3 integration u...   \n",
       "\n",
       "                             retrieved_context_stuff  tokens  \n",
       "0  `wandb.init()` returns a run object, and you c...   15505  \n",
       "1  ### How do I best log models from runs in a sw...   13161  \n",
       "2  ### Model Architecture\\n\\nOur config also defi...   17812  \n",
       "3   # A 3-in-1 Intro to Weights & Biases: Compute...   12755  \n",
       "4  ## Basic Example\\n\\nThe W&B SB3 integration us...   15480  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24f78893-9828-4c35-b5e6-a84b5a32134b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_df = eval_df[[\"query\", \"generated_response\", \"retrieved_context_stuff\", \"tokens\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70e8f2c5-1c1a-4cc7-9419-bf2e8749cb9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_df.columns = [\"question\", \"answer\", \"retrieved_context\", \"char_len\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "79fa4de5-5c6e-4b73-aaa5-4dd528dec187",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>retrieved_context</th>\n",
       "      <th>char_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hey I have a question about using wandb with f...</td>\n",
       "      <td>The initialization of `wandb.init()` should be...</td>\n",
       "      <td>`wandb.init()` returns a run object, and you c...</td>\n",
       "      <td>15505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey with wandb is it possible to link from the...</td>\n",
       "      <td>Yes, you can link to the best run from a sweep...</td>\n",
       "      <td>### How do I best log models from runs in a sw...</td>\n",
       "      <td>13161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am training a spacy textcat model. This proc...</td>\n",
       "      <td>To log the best model's metrics instead of the...</td>\n",
       "      <td>### Model Architecture\\n\\nOur config also defi...</td>\n",
       "      <td>17812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Explain how I can version datasets with Weight...</td>\n",
       "      <td>Weights &amp; Biases provides a feature called Art...</td>\n",
       "      <td># A 3-in-1 Intro to Weights &amp; Biases: Compute...</td>\n",
       "      <td>12755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm using   env = SubprocVecEnv(\\n        [mak...</td>\n",
       "      <td>To record a video for a specific subprocess en...</td>\n",
       "      <td>## Basic Example\\n\\nThe W&amp;B SB3 integration us...</td>\n",
       "      <td>15480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Hey I have a question about using wandb with f...   \n",
       "1  Hey with wandb is it possible to link from the...   \n",
       "2  I am training a spacy textcat model. This proc...   \n",
       "3  Explain how I can version datasets with Weight...   \n",
       "4  I'm using   env = SubprocVecEnv(\\n        [mak...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  The initialization of `wandb.init()` should be...   \n",
       "1  Yes, you can link to the best run from a sweep...   \n",
       "2  To log the best model's metrics instead of the...   \n",
       "3  Weights & Biases provides a feature called Art...   \n",
       "4  To record a video for a specific subprocess en...   \n",
       "\n",
       "                                   retrieved_context  char_len  \n",
       "0  `wandb.init()` returns a run object, and you c...     15505  \n",
       "1  ### How do I best log models from runs in a sw...     13161  \n",
       "2  ### Model Architecture\\n\\nOur config also defi...     17812  \n",
       "3   # A 3-in-1 Intro to Weights & Biases: Compute...     12755  \n",
       "4  ## Basic Example\\n\\nThe W&B SB3 integration us...     15480  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f8de07-59c4-40f0-810b-7a1805ab5a8a",
   "metadata": {},
   "source": [
    "## Save to W&B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108ce808-876b-404d-bc98-eba585672252",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's format the dataset in the same way we created the training dataset, we have to be consisten with naming\n",
    "- We remove the answer, but we are going to keep it on the dataset to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "664f5165-0d3d-4e19-b237-2d9c198c5c1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "B_INST, E_INST = \"[INST] \", \" [/INST]\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "EOS = \"</s>\"\n",
    "\n",
    "prompt_format = (\n",
    "    B_INST\n",
    "    + B_SYS\n",
    "    + \"You are an AI assistant designed to assist developers with everyday tasks related to Weight & Biases\"\n",
    "    + \"and provide helpful information. As an expert in the open-source python SDK wandb answer the following\"\n",
    "    # + \"question based on the context below. Answer in formatted Markdown.\\n\"\n",
    "    + \"question below. Answer in formatted Markdown.\\n\"\n",
    "    + \"{page_content}\"\n",
    "    + E_SYS\n",
    "    + \"{question}\"\n",
    "    + E_INST\n",
    "    + \"\\n[W&B]\\n\"\n",
    "    # + \"{answer}\"\n",
    "    # + \"\\n[/W&B]\"\n",
    "    # + EOS\n",
    ")\n",
    "\n",
    "def format_text(row):\n",
    "    return prompt_format.format_map(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50e7ff7d-27fe-4e9d-b04a-98a9494387c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_df = eval_df.rename({\"retrieved_context\":\"page_content\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b6c968a-892d-4d76-a921-63a473bc71dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47e8c90622574ed0a94d81fd41dd7d91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adcfa3570d92479bbe3e8ebe4960f63b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e19ad3dd1ea4980990e8cde2246ab98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_dataset = []\n",
    "for index, row in df.iterrows():\n",
    "    eval_dataset.append({**row, \"text\": format_text_eval(row)})\n",
    "\n",
    "save_jsonl(eval_dataset, filename=\"wandbot_eval.jsonl\")\n",
    "\n",
    "eval_dataset = load_dataset(\".\", data_files=\"wandbot_eval.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3dd86384-2cae-41f8-83a5-6597242244db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train_dataset to s3\n",
    "if USE_S3:\n",
    "    eval_input_path = f's3://{sess.default_bucket()}/processed/wandbot/eval'\n",
    "else:\n",
    "    eval_input_path = \"./wandbot_eval_ds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a4c5caf-c577-4360-881d-ef36b5bb39d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9807cb8f61c74cb8982d5ab2b0a4092f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1026 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_dataset.save_to_disk(eval_input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d615bb7-f385-4771-a593-c2845561d0fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "at = wandb.Artifact(\n",
    "    name=\"wandbot_eval_dataset\", \n",
    "    type=\"dataset\",\n",
    "    description=\"A wandbot dataset of questions and answers about W&B for evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b87fb8c-c12e-4f63-b9d2-6ef7d014db1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/sagemaker-llama2-wandb/training/wandb/run-20231017_083818-lgx9ekjo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/capecape/aws_llm_demo/runs/lgx9ekjo' target=\"_blank\">vivid-tree-28</a></strong> to <a href='https://wandb.ai/capecape/aws_llm_demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/capecape/aws_llm_demo' target=\"_blank\">https://wandb.ai/capecape/aws_llm_demo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/capecape/aws_llm_demo/runs/lgx9ekjo' target=\"_blank\">https://wandb.ai/capecape/aws_llm_demo/runs/lgx9ekjo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Generating checksum for up to 10000 objects in \"sagemaker-us-east-1-372108735839/processed/wandbot/eval\"... Done. 0.1s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "477eed83cb8e46dda3c338991f44b0a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.368 MB of 0.368 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vivid-tree-28</strong> at: <a href='https://wandb.ai/capecape/aws_llm_demo/runs/lgx9ekjo' target=\"_blank\">https://wandb.ai/capecape/aws_llm_demo/runs/lgx9ekjo</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231017_083818-lgx9ekjo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with wandb.init(project=WANDB_PROJECT, job_type=\"preprocessing\"):\n",
    "    if USE_S3:\n",
    "        at.add_reference(eval_input_path)\n",
    "    else:\n",
    "        at.add_dir(eval_input_path)\n",
    "    wandb.log_artifact(at)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

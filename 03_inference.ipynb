{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16bcbd84-d698-4346-aa07-95e13e754e5b",
   "metadata": {},
   "source": [
    "# Running Inference of your FT model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d8e5cd-cbc7-4dae-bdbb-07b159361a0f",
   "metadata": {},
   "source": [
    "## SageMaker auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d21cc52-1b97-4629-9044-4d076e60cb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "DATASET_S3 = f's3://{sess.default_bucket()}/processed/wandbot/train'\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726daffc-3498-49e9-9664-a12712004701",
   "metadata": {},
   "source": [
    "## Creating the Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee1bddc-4f68-4055-8824-2b43ce41ed44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "\n",
    "# retrieve the llm image uri\n",
    "llm_image = get_huggingface_llm_image_uri(\n",
    "  \"huggingface\",\n",
    "  version=\"1.1.0\",\n",
    "  session=sess,\n",
    ")\n",
    "\n",
    "# print ecr image uri\n",
    "print(f\"llm image uri: {llm_image}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b47162c-b559-4e19-937c-cece0334331f",
   "metadata": {},
   "source": [
    "Lets create the endpoint with the model stored on S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bd5ae1-5315-4d6d-9563-eef6a6c1eb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_s3_path = \"s3://sagemaker-us-east-1-372108735839/wandb-qlora-codellama7-2023-10-26-00-01-56-374/output/model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b21176-4820-4c21-887a-bb811981d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "# s3 path where the model will be uploaded\n",
    "# if you try to deploy the model to a different time add the s3 path here\n",
    "# model_s3_path = huggingface_estimator.model_data[\"S3DataSource\"][\"S3Uri\"]\n",
    "\n",
    "# sagemaker config\n",
    "instance_type = \"ml.g5.2xlarge\"\n",
    "number_of_gpu = 1\n",
    "health_check_timeout = 300\n",
    "\n",
    "# Define Model and Endpoint configuration parameter\n",
    "config = {\n",
    "  'HF_MODEL_ID': \"/opt/ml/model\", # path to where sagemaker stores the model\n",
    "  'SM_NUM_GPUS': json.dumps(number_of_gpu), # Number of GPU used per replica\n",
    "  'MAX_INPUT_LENGTH': json.dumps(2048), # Max length of input text\n",
    "  'MAX_TOTAL_TOKENS': json.dumps(3000), # Max length of the generation (including input text)\n",
    "}\n",
    "\n",
    "# create HuggingFaceModel with the image uri\n",
    "llm_model = HuggingFaceModel(\n",
    "  role=role,\n",
    "  image_uri=llm_image,\n",
    "  model_data={'S3DataSource':{'S3Uri': model_s3_path,'S3DataType': 'S3Prefix','CompressionType': 'None'}},\n",
    "  env=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16e368a-3322-4c23-80ce-b4980113f6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy model to an endpoint\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.Model.deploy\n",
    "llm = llm_model.deploy(\n",
    "  initial_instance_count=1,\n",
    "  instance_type=instance_type,\n",
    "  container_startup_health_check_timeout=health_check_timeout, # 10 minutes to be able to load the model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1dc7c5-33a5-420f-8e62-aa77aaf29c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6876547-1f1e-4bd9-8a90-5eb4c8d7f8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = sess.boto_session\n",
    "smr = session.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105ef38c-5a9b-4866-9be2-ae105ea8d3a9",
   "metadata": {},
   "source": [
    "## Eval Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fc9185-f4b1-4238-9acf-20dfe81b9815",
   "metadata": {},
   "source": [
    "I recommend reading this [excellent blog post](https://www.philschmid.de/sagemaker-falcon-180b) to understand the ins and outs of deploying to SageMaker with Huggingface models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534bc0df-0fa9-4310-be66-01524e117ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qqqU wandb datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef6f5f9-74d9-4fa3-a1b9-f8977a301d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "WANDB_PROJECT = \"aws_llm_workshop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d48aaf2-4fcf-4200-83ea-654b15c156f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import json\n",
    "from datasets import load_from_disk\n",
    "run = wandb.init(project=WANDB_PROJECT, job_type=\"inference\")\n",
    "artifact = run.use_artifact('capecape/aws_llm_workshop/wandbot_eval_dataset:v1', type='dataset')\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dfe84d-a3f2-4b5f-b2c0-42a6b9fe7387",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ds = load_from_disk(artifact_dir)[\"train\"]  # I know, it has a split named train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee07d36-d2b2-4a6b-a8fb-ea55f66c8a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_sample = eval_ds[0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36907374-9511-4acd-a7d8-516ac0a79435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatted_prompt = format_prompt(prompt, history, system_prompt)\n",
    "import json\n",
    "\n",
    "# hyperparameters for llm\n",
    "parameters = {\n",
    "    \"do_sample\": True,\n",
    "    \"top_p\": 0.9,\n",
    "    \"temperature\": 0.8,\n",
    "    \"max_new_tokens\": 952,\n",
    "    \"repetition_penalty\": 1.03,\n",
    "    \"stop\": [\"[/W&B]\", \"</s>\"],\n",
    "}\n",
    "\n",
    "# hyperparameters for llm\n",
    "payload = {\n",
    "  \"inputs\": one_sample,\n",
    "  \"parameters\": parameters,\n",
    "}\n",
    "\n",
    "# send request to endpoint\n",
    "response = llm.predict(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b78364-e6b5-4bbd-940b-9237d430a5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = response[0][\"generated_text\"]\n",
    "print(assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a292cc8-f5d7-4b0a-a278-0fb0002fa64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "\n",
    "def call_endpoint(formatted_input, parameters):\n",
    "    \"Call the SM endpoint and parse the output in string format\"\n",
    "    t0 = perf_counter()\n",
    "    payload = {\n",
    "      \"inputs\": formatted_input,\n",
    "      \"parameters\": parameters,\n",
    "    }\n",
    "    response = llm.predict(payload)\n",
    "    total_time = perf_counter() - t0\n",
    "\n",
    "    return response[0][\"generated_text\"], total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d816664-db91-4659-806f-9977704a8ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_endpoint(one_sample, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf263311-3a0c-4583-9eb7-aae3f5aff7a6",
   "metadata": {},
   "source": [
    "## Saving our eval results to W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010c7b7a-6c7a-411a-808a-709a7ab618d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1efab40-2b53-4e89-a578-cbd85144f7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_cols = list(parameters.keys())\n",
    "table = wandb.Table(columns=[\"question\", \"original_answer\", \"generated_answer\", \"time(s)\"] + params_cols) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ad2166-e508-49cc-a21c-a71f166124a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in tqdm(eval_ds):\n",
    "    generated_answer, req_time = call_endpoint(s[\"text\"], parameters)\n",
    "    table.add_data(s[\"question\"], s[\"answer\"], generated_answer, req_time, *list(parameters.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cefc701-da4b-46bf-ab7f-cfa4b2ef0bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\"evaluation_answers\": table})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0cd080-dc4c-454e-8b19-8ec9423a3018",
   "metadata": {},
   "source": [
    "don't forget to kill the endopoint! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983a1771-0a99-4c76-ad09-ccef990bc638",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.delete_model()\n",
    "llm.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
